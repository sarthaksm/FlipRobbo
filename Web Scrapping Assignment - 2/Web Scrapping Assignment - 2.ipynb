{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9262bc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\sarth\\anaconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sarth\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "#installing selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e867dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries and drivers\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException , NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b454e",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8e0e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver = webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148b9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get driver to visit defined URL\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cfd6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input in the “Skill, Designations, Companies” bar\n",
    "skill = driver.find_element(By.XPATH,'//input[@class=\"suggestor-input \"]')\n",
    "skill.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "253ffb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input in the location bar\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc8bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the search button\n",
    "search=driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa60d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Loaction</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business &amp; Data Analyst- Assistant Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr. Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Clinical Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Manager / Senior Manager - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Title  \\\n",
       "1   Business & Data Analyst- Assistant Manager   \n",
       "2                    Sr. Business Data Analyst   \n",
       "3                          Senior Data Analyst   \n",
       "4                     Sr Clinical Data Analyst   \n",
       "5      Manager / Senior Manager - Data Analyst   \n",
       "6                                 Data Analyst   \n",
       "7                                 Data Analyst   \n",
       "8                          Senior Data Analyst   \n",
       "9                             Sr. Data Analyst   \n",
       "10                         Senior Data Analyst   \n",
       "\n",
       "                                         Job Location  \\\n",
       "1         Bangalore/Bengaluru, Hyderabad/Secunderabad   \n",
       "2                                 Bangalore/Bengaluru   \n",
       "3                                 Bangalore/Bengaluru   \n",
       "4                                 Bangalore/Bengaluru   \n",
       "5   Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "6                      Bangalore/Bengaluru, Ahmedabad   \n",
       "7                                 Bangalore/Bengaluru   \n",
       "8                Bangalore/Bengaluru(Old Madras Road)   \n",
       "9                           Bangalore/Bengaluru, Pune   \n",
       "10                                Bangalore/Bengaluru   \n",
       "\n",
       "                                     Company Loaction Experience Required  \n",
       "1         Bangalore/Bengaluru, Hyderabad/Secunderabad             1-3 Yrs  \n",
       "2                                 Bangalore/Bengaluru             4-6 Yrs  \n",
       "3                                 Bangalore/Bengaluru             5-8 Yrs  \n",
       "4                                 Bangalore/Bengaluru             2-5 Yrs  \n",
       "5   Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...             2-7 Yrs  \n",
       "6                      Bangalore/Bengaluru, Ahmedabad             2-7 Yrs  \n",
       "7                                 Bangalore/Bengaluru             2-5 Yrs  \n",
       "8                Bangalore/Bengaluru(Old Madras Road)             3-6 Yrs  \n",
       "9                           Bangalore/Bengaluru, Pune            6-11 Yrs  \n",
       "10                                Bangalore/Bengaluru             5-7 Yrs  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "location=[]\n",
    "company=[]\n",
    "exp=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')[0:10]: #scrapping 10 jobs title from page\n",
    "    title.append(i.text)\n",
    "    \n",
    "for j in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')[0:10]: #scrapping 10 location details from page\n",
    "    location.append(j.text)\n",
    "\n",
    "for k in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:10]: #scrapping 10 company name from page\n",
    "    company.append(k.text)\n",
    "    \n",
    "for l in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')[0:10]: #scrapping 10 job's experience required from site\n",
    "    exp.append(l.text)\n",
    "    \n",
    "df=pd.DataFrame({'Job Title':title, 'Job Location':location, 'Company Loaction': location, 'Experience Required':exp}) #converting scrapped data into dataframe\n",
    "df.index=np.arange(1,len(df)+1) #inserting indexing\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59db760",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "607478bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver = webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e255e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get driver to visit defined URL\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3579bf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input in the “Skill, Designations, Companies” bar\n",
    "skill = driver.find_element(By.CLASS_NAME,'suggestor-input ')\n",
    "skill.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b94de30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input in the location bar\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c40ed8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the search button\n",
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36fae3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Manager - EmTech - Machine Learning - P&amp;T</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data scientist _Tata Consultancy Services(Tcs)</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, Indore, New...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For DATA Scientist @ NTT DATA Business ...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>NTT DATA Business Solutions Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tcs Hiring For Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai, Mumbai (All Areas)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Lead_Tata Consultancy Services(...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1                                   Lead ML Scientist   \n",
       "2    Senior Manager - EmTech - Machine Learning - P&T   \n",
       "3                    Analystics & Modeling Specialist   \n",
       "4      Data scientist _Tata Consultancy Services(Tcs)   \n",
       "5   Job||Job Opening For AI Technologist - Data Sc...   \n",
       "6   Hiring For DATA Scientist @ NTT DATA Business ...   \n",
       "7                       Tcs Hiring For Data Scientist   \n",
       "8   Urgent Job Opening For AI Practitioner - Data ...   \n",
       "9   Data Scientist Lead_Tata Consultancy Services(...   \n",
       "10                   Assistant Manager - Data Science   \n",
       "\n",
       "                                         Job Location  \\\n",
       "1                         Bangalore/Bengaluru, Mumbai   \n",
       "2   Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "3   Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "4   Bangalore/Bengaluru, Kochi/Cochin, Indore, New...   \n",
       "5   Bangalore/Bengaluru, New Delhi, Hyderabad/Secu...   \n",
       "6   Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "7    Bangalore/Bengaluru, Chennai, Mumbai (All Areas)   \n",
       "8   Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "9   Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "10                  Bangalore/Bengaluru, Mumbai, Pune   \n",
       "\n",
       "                                   Company Name  \n",
       "1                             Fractal Analytics  \n",
       "2                                           PwC  \n",
       "3                                     Accenture  \n",
       "4               TATA CONSULTANCY SERVICES (TCS)  \n",
       "5                                         Wipro  \n",
       "6   NTT DATA Business Solutions Private Limited  \n",
       "7               TATA CONSULTANCY SERVICES (TCS)  \n",
       "8                                         Wipro  \n",
       "9               TATA CONSULTANCY SERVICES (TCS)  \n",
       "10                                   CitiusTech  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "location=[]\n",
    "company=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')[0:10]: #scrapping 10 jobs title from page\n",
    "    title.append(i.text)\n",
    "    \n",
    "for j in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')[0:10]: #scrapping 10 location details from page\n",
    "    location.append(j.text)\n",
    "    \n",
    "for k in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:10]: #scrapping 10 company name from page\n",
    "    company.append(k.text)\n",
    "    \n",
    "df1=pd.DataFrame({'Job Title':title, 'Job Location':location, 'Company Name':company}) #converting scrapped data into dataframe\n",
    "df1.index=np.arange(1,len(df1)+1) #inserting index numbers\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8233eee2",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b932e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver = webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc877396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get driver to visit defined URL\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a62f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input in the “Skill, Designations, and Companies” bar\n",
    "skill = driver.find_element(By.CLASS_NAME,'suggestor-input ')\n",
    "skill.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cc716dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on search button\n",
    "search = driver.find_element(By.XPATH,'//div[@class=\"qsbSubmit\"]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d50b7258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying filter for \"Delhi/NCR\" location\n",
    "loc=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[3]/label/i')\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56b0f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying salary \"3-6” filter\n",
    "sal=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/i')\n",
    "sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbfeb97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job||Job Opening For AI Technologist - Data Sc...</td>\n",
       "      <td>New Delhi, Hyderabad/Secunderabad, Pune, Chenn...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Predictive Analytics</td>\n",
       "      <td>Noida, Mumbai, Chandigarh, Hyderabad/Secundera...</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chat-bot Developer / Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Bangalore/Bengaluru\\n(WFH d...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Feedback Infra</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Title  \\\n",
       "1   Job||Job Opening For AI Technologist - Data Sc...   \n",
       "2               Data Scientist - Predictive Analytics   \n",
       "3                    Data Scientist - Noida/Bangalore   \n",
       "4                     DigitalBCG GAMMA Data Scientist   \n",
       "5                   Data Scientist - Engine Algorithm   \n",
       "6                                      Data Scientist   \n",
       "7                 Chat-bot Developer / Data Scientist   \n",
       "8                                      Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10                Data Scientist / Chat-bot Developer   \n",
       "\n",
       "                                         Job Location  \\\n",
       "1   New Delhi, Hyderabad/Secunderabad, Pune, Chenn...   \n",
       "2   Noida, Mumbai, Chandigarh, Hyderabad/Secundera...   \n",
       "3                          Noida, Bangalore/Bengaluru   \n",
       "4                      New Delhi, Bangalore/Bengaluru   \n",
       "5   Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "6                                    Gurgaon/Gurugram   \n",
       "7   Mumbai, New Delhi, Bangalore/Bengaluru\\n(WFH d...   \n",
       "8                                    Gurgaon/Gurugram   \n",
       "9              Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "10  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...   \n",
       "\n",
       "                               Company Name Experience Required  \n",
       "1                                     Wipro            5-10 Yrs  \n",
       "2                              Confidential             1-6 Yrs  \n",
       "3                                       EXL            5-10 Yrs  \n",
       "4                   Boston Consulting Group             2-5 Yrs  \n",
       "5                              Primo Hiring             1-3 Yrs  \n",
       "6                                     Optum             2-7 Yrs  \n",
       "7                              Big Seo Buzz             2-7 Yrs  \n",
       "8                            Feedback Infra             2-4 Yrs  \n",
       "9   Mount Talent Consulting Private Limited             2-4 Yrs  \n",
       "10                             Big Seo Buzz             3-7 Yrs  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "location=[]\n",
    "company=[]\n",
    "exp=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')[0:10]: #scrapping 10 jobs title from page\n",
    "    title.append(i.text)\n",
    "    \n",
    "for j in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')[0:10]: #scrapping 10 location data from page\n",
    "    location.append(j.text)\n",
    "    \n",
    "for k in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:10]: #scrapping 10 company name from page\n",
    "    company.append(k.text)\n",
    "    \n",
    "for l in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')[0:10]: #scrapping 10 experience data from page\n",
    "    exp.append(l.text)\n",
    "\n",
    "df1=pd.DataFrame({'Job Title':title, 'Job Location':location, 'Company Name':company, 'Experience Required':exp}) #converting scrapped data into dataframe\n",
    "df1.index=np.arange(1,len(df1)+1) #inserting index numbers\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb18bb",
   "metadata": {},
   "source": [
    "Q4. Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b34c4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffd68e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get driver to visit defined URL\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5fe2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing the ad on the page\n",
    "ad_close=driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "ad_close.click()\n",
    "\n",
    "#inserting command in the search bar\n",
    "sea=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "sea.send_keys('Sunglasses')\n",
    "\n",
    "#click on the search button\n",
    "sear=driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "sear.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc7da3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount Offered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹849</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹298</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹252</td>\n",
       "      <td>90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹949</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Oval Sunglasses (58)</td>\n",
       "      <td>₹498</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (55)</td>\n",
       "      <td>₹3,289</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹268</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Aviator Sunglasses (53)</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand Name                                Product Description   Price  \\\n",
       "1    VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹999   \n",
       "2    VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...    ₹849   \n",
       "3         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹799   \n",
       "4        Elligator                UV Protection Round Sunglasses (54)    ₹298   \n",
       "5           PIRASO          UV Protection Rectangular Sunglasses (52)    ₹252   \n",
       "..             ...                                                ...     ...   \n",
       "96   VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹949   \n",
       "97          AISLIN       UV Protection, Gradient Oval Sunglasses (58)    ₹498   \n",
       "98         Ray-Ban         UV Protection Retro Square Sunglasses (55)  ₹3,289   \n",
       "99       New Specs         UV Protection Round Sunglasses (Free Size)    ₹268   \n",
       "100  VINCENT CHASE  by Lenskart UV Protection Aviator Sunglasses (53)    ₹999   \n",
       "\n",
       "    Discount Offered  \n",
       "1            50% off  \n",
       "2            57% off  \n",
       "3            20% off  \n",
       "4            88% off  \n",
       "5            90% off  \n",
       "..               ...  \n",
       "96           52% off  \n",
       "97           67% off  \n",
       "98           40% off  \n",
       "99           79% off  \n",
       "100          50% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=[]\n",
    "prod1=[]\n",
    "prod2=[]\n",
    "price=[]\n",
    "dis=[]\n",
    "start= 0\n",
    "end= 3\n",
    "\n",
    "for page in range(start,end):\n",
    "    tit=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    su1=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "    su2=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    pr=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    ds=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    \n",
    "    for j in tit: #scrapping brand data from page\n",
    "        brand.append(j.text)\n",
    "        \n",
    "    for k in su1: #scrapping product name data with one class name from page\n",
    "        prod1.append(k.text)\n",
    "        \n",
    "    for m in su2: #scrapping product name data with second class name from page\n",
    "        prod2.append(m.text)\n",
    "        prod=prod1+prod2\n",
    "        \n",
    "    for l in pr: #scrapping price data from page\n",
    "        price.append(l.text)\n",
    "        \n",
    "    for i in ds: #scrapping discoutn data from page\n",
    "        dis.append(i.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,\"//a[@class='ge-49M']\") #scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[page].get_attribute('href')) #getting the link from the list for next page\n",
    "    except:\n",
    "        print(\"Page not found\")\n",
    "        \n",
    "\n",
    "df=pd.DataFrame({'Brand Name':brand,'Product Description':prod, 'Price':price, 'Discount Offered':dis}) #converting scrapped data into dataframe\n",
    "df.index=np.arange(1,len(df)+1) #inserting index numbers\n",
    "df.head(100) #slicing data to show only top 100 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd307f8",
   "metadata": {},
   "source": [
    "Q5: Scrape 50 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "3. Then click the search button.\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for 50 reviews. (SME Updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7cb37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2af0e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get driver to visit defined URL\n",
    "driver.get('https://www.flipkart.com/apple-iphone-12-black-128-gb/product-reviews/itmf1f0a58f1ecd7?pid=MOBFWBYZK3HACR72&lid=LSTMOBFWBYZK3HACR72PX4KSA&marketplace=FLIPKART ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b5bce78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Summary Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Wow superb camera phone\\nVery smooth speed and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>The brand is very trustworthy and i got genuin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Awesome phone … value for money.. Happy with b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Guys ,this is just Beast at Every Aspect of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanx flipkart for value super sale for short ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Excellent product worth for every penny, writi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Thanks flipkart i trust you got my device perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Top class performance and battery backup too. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Almost 1month of purshase and i am loving it ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>My 1st iPhone ever and I’m loving it. Great pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Wow superb camera phone\\nVery smooth speed and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>The brand is very trustworthy and i got genuin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Awesome phone … value for money.. Happy with b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Guys ,this is just Beast at Every Aspect of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanx flipkart for value super sale for short ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Excellent product worth for every penny, writi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Thanks flipkart i trust you got my device perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Top class performance and battery backup too. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Almost 1month of purshase and i am loving it ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>My 1st iPhone ever and I’m loving it. Great pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Wow superb camera phone\\nVery smooth speed and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>The brand is very trustworthy and i got genuin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Awesome phone … value for money.. Happy with b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Guys ,this is just Beast at Every Aspect of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanx flipkart for value super sale for short ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Excellent product worth for every penny, writi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Thanks flipkart i trust you got my device perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Top class performance and battery backup too. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Almost 1month of purshase and i am loving it ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>My 1st iPhone ever and I’m loving it. Great pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Wow superb camera phone\\nVery smooth speed and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>The brand is very trustworthy and i got genuin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Awesome phone … value for money.. Happy with b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Guys ,this is just Beast at Every Aspect of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanx flipkart for value super sale for short ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Excellent product worth for every penny, writi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Thanks flipkart i trust you got my device perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Top class performance and battery backup too. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Almost 1month of purshase and i am loving it ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>My 1st iPhone ever and I’m loving it. Great pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>I really m glad that i went for i phone in pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Delightful phone, the phone is just a peice of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best in every department. ❤️\\nI upgraded on iP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Perfect phone , Apple after all\\nGo for it eye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>This was an awesome buy. I bought this phone f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>Excellent product worth every penny right this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>iPhone 6S Plus 64GB -&gt; iPhone 12 128GB\\nMy 2nd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Switched from Android to iPhone and this trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Night mode is simply amazing and give you a cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>I bought this iphone 12 in big billion days an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Summary Review  \\\n",
       "1       5               Terrific   \n",
       "2       5       Perfect product!   \n",
       "3       5      Terrific purchase   \n",
       "4       5  Mind-blowing purchase   \n",
       "5       5     Highly recommended   \n",
       "6       5                Awesome   \n",
       "7       5                Awesome   \n",
       "8       5              Must buy!   \n",
       "9       5              Brilliant   \n",
       "10      5     Highly recommended   \n",
       "11      5               Terrific   \n",
       "12      5       Perfect product!   \n",
       "13      5      Terrific purchase   \n",
       "14      5  Mind-blowing purchase   \n",
       "15      5     Highly recommended   \n",
       "16      5                Awesome   \n",
       "17      5                Awesome   \n",
       "18      5              Must buy!   \n",
       "19      5              Brilliant   \n",
       "20      5     Highly recommended   \n",
       "21      5               Terrific   \n",
       "22      5       Perfect product!   \n",
       "23      5      Terrific purchase   \n",
       "24      5  Mind-blowing purchase   \n",
       "25      5     Highly recommended   \n",
       "26      5                Awesome   \n",
       "27      5                Awesome   \n",
       "28      5              Must buy!   \n",
       "29      5              Brilliant   \n",
       "30      5     Highly recommended   \n",
       "31      5               Terrific   \n",
       "32      5       Perfect product!   \n",
       "33      5      Terrific purchase   \n",
       "34      5  Mind-blowing purchase   \n",
       "35      5     Highly recommended   \n",
       "36      5                Awesome   \n",
       "37      5                Awesome   \n",
       "38      5              Must buy!   \n",
       "39      5              Brilliant   \n",
       "40      5     Highly recommended   \n",
       "41      5              Must buy!   \n",
       "42      5              Must buy!   \n",
       "43      5      Worth every penny   \n",
       "44      5              Just wow!   \n",
       "45      5               Terrific   \n",
       "46      5              Brilliant   \n",
       "47      5              Just wow!   \n",
       "48      5                Awesome   \n",
       "49      5          Great product   \n",
       "50      4            Pretty good   \n",
       "\n",
       "                                          Full Review  \n",
       "1   Wow superb camera phone\\nVery smooth speed and...  \n",
       "2   The brand is very trustworthy and i got genuin...  \n",
       "3   Awesome phone … value for money.. Happy with b...  \n",
       "4   Guys ,this is just Beast at Every Aspect of Co...  \n",
       "5   Thanx flipkart for value super sale for short ...  \n",
       "6   Excellent product worth for every penny, writi...  \n",
       "7   Thanks flipkart i trust you got my device perf...  \n",
       "8   Top class performance and battery backup too. ...  \n",
       "9   Almost 1month of purshase and i am loving it ....  \n",
       "10  My 1st iPhone ever and I’m loving it. Great pe...  \n",
       "11  Wow superb camera phone\\nVery smooth speed and...  \n",
       "12  The brand is very trustworthy and i got genuin...  \n",
       "13  Awesome phone … value for money.. Happy with b...  \n",
       "14  Guys ,this is just Beast at Every Aspect of Co...  \n",
       "15  Thanx flipkart for value super sale for short ...  \n",
       "16  Excellent product worth for every penny, writi...  \n",
       "17  Thanks flipkart i trust you got my device perf...  \n",
       "18  Top class performance and battery backup too. ...  \n",
       "19  Almost 1month of purshase and i am loving it ....  \n",
       "20  My 1st iPhone ever and I’m loving it. Great pe...  \n",
       "21  Wow superb camera phone\\nVery smooth speed and...  \n",
       "22  The brand is very trustworthy and i got genuin...  \n",
       "23  Awesome phone … value for money.. Happy with b...  \n",
       "24  Guys ,this is just Beast at Every Aspect of Co...  \n",
       "25  Thanx flipkart for value super sale for short ...  \n",
       "26  Excellent product worth for every penny, writi...  \n",
       "27  Thanks flipkart i trust you got my device perf...  \n",
       "28  Top class performance and battery backup too. ...  \n",
       "29  Almost 1month of purshase and i am loving it ....  \n",
       "30  My 1st iPhone ever and I’m loving it. Great pe...  \n",
       "31  Wow superb camera phone\\nVery smooth speed and...  \n",
       "32  The brand is very trustworthy and i got genuin...  \n",
       "33  Awesome phone … value for money.. Happy with b...  \n",
       "34  Guys ,this is just Beast at Every Aspect of Co...  \n",
       "35  Thanx flipkart for value super sale for short ...  \n",
       "36  Excellent product worth for every penny, writi...  \n",
       "37  Thanks flipkart i trust you got my device perf...  \n",
       "38  Top class performance and battery backup too. ...  \n",
       "39  Almost 1month of purshase and i am loving it ....  \n",
       "40  My 1st iPhone ever and I’m loving it. Great pe...  \n",
       "41  I really m glad that i went for i phone in pla...  \n",
       "42  Delightful phone, the phone is just a peice of...  \n",
       "43  Best in every department. ❤️\\nI upgraded on iP...  \n",
       "44  Perfect phone , Apple after all\\nGo for it eye...  \n",
       "45  This was an awesome buy. I bought this phone f...  \n",
       "46  Excellent product worth every penny right this...  \n",
       "47  iPhone 6S Plus 64GB -> iPhone 12 128GB\\nMy 2nd...  \n",
       "48  Switched from Android to iPhone and this trans...  \n",
       "49  Night mode is simply amazing and give you a cl...  \n",
       "50  I bought this iphone 12 in big billion days an...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rat1=[]\n",
    "summ1=[]\n",
    "full1=[]\n",
    "start=1\n",
    "end=2\n",
    "rat2=[]\n",
    "summ2=[]\n",
    "full2=[]\n",
    "start2=4\n",
    "end2=6\n",
    "rat3=[]\n",
    "summ3=[]\n",
    "full3=[]\n",
    "start3=8\n",
    "end3=10\n",
    "\n",
    "for page in range(start,end):\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]'): #scrapping rating data from page\n",
    "        rat1.append(i.text)\n",
    "        \n",
    "    for j in driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]'): #scrapping review summary from page\n",
    "        summ1.append(j.text)\n",
    "        \n",
    "    for k in driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]'): #scrapping full review from page\n",
    "        full1.append(k.text)\n",
    "        \n",
    "for page in range(start2,end2):\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]'): #scrapping rating data from page\n",
    "        rat2.append(i.text)\n",
    "        \n",
    "    for j in driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]'): #scrapping review summary from page\n",
    "        summ2.append(j.text)\n",
    "        \n",
    "    for k in driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]'): #scrapping full review from page\n",
    "        full2.append(k.text)\n",
    "        \n",
    "for page in range(start3,end3):\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]'): #scrapping rating data from page\n",
    "        rat3.append(i.text)\n",
    "        \n",
    "    for j in driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]'): #scrapping review summary from page\n",
    "        summ3.append(j.text)\n",
    "        \n",
    "    for k in driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]'): #scrapping full review from page\n",
    "        full3.append(k.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]') #scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "\n",
    "#summing up all the scrapped data\n",
    " \n",
    "rat = rat1+rat2+rat3 \n",
    "summ=summ1+summ2+summ3\n",
    "full=full1+full2+full3\n",
    "\n",
    "df=pd.DataFrame({'Rating':rat, 'Summary Review':summ, 'Full Review':full}) #converting scrapped data into dataframe\n",
    "df.index=np.arange(1,len(df)+1) #inserting index numbers\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3db8c",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b2f85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24c42703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get driver to visit defined URL\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3efeeb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing ad on the page\n",
    "ad_close=driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]')\n",
    "ad_close.click()\n",
    "\n",
    "#inserting command in the search bar\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search.send_keys('sneakers')\n",
    "\n",
    "#click on the search button\n",
    "search_button=driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7560ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Item Price</th>\n",
       "      <th>Discount Offered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Easy Vulc 2.0 Sneakers For Men</td>\n",
       "      <td>₹1,305</td>\n",
       "      <td>67% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Mesh | Ultralightweight | Comfortable | Breath...</td>\n",
       "      <td>₹630</td>\n",
       "      <td>36% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹374</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Puma Smash Wns v2 L Sneakers For Women</td>\n",
       "      <td>₹373</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹1,542</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>Trendy Fashion Sports Combo Pack Of 3 Pairs Ou...</td>\n",
       "      <td>₹1,683</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Latest Women's Pack of 2 Stylish Slip-On Loafe...</td>\n",
       "      <td>₹1,948</td>\n",
       "      <td>44% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Xtoon</td>\n",
       "      <td>Puma Smash v2 L Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>aadi</td>\n",
       "      <td>VS PACE Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>bacca bucci</td>\n",
       "      <td>Shoes For Women's/Ladies/Female/Girls Running ...</td>\n",
       "      <td>₹1,578</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand Name                                       Product Name  \\\n",
       "1         ADIDAS                     Easy Vulc 2.0 Sneakers For Men   \n",
       "2       RapidBox  Mesh | Ultralightweight | Comfortable | Breath...   \n",
       "3           aadi                                 Sneakers For Women   \n",
       "4      Deals4you             Puma Smash Wns v2 L Sneakers For Women   \n",
       "5           PUMA  Super Stylish & Trendy Combo Pack of 02 Pairs ...   \n",
       "..           ...                                                ...   \n",
       "96   bacca bucci  Trendy Fashion Sports Combo Pack Of 3 Pairs Ou...   \n",
       "97          PUMA  Latest Women's Pack of 2 Stylish Slip-On Loafe...   \n",
       "98         Xtoon                   Puma Smash v2 L Sneakers For Men   \n",
       "99          aadi                           VS PACE Sneakers For Men   \n",
       "100  bacca bucci  Shoes For Women's/Ladies/Female/Girls Running ...   \n",
       "\n",
       "    Item Price Discount Offered  \n",
       "1       ₹1,305          67% off  \n",
       "2         ₹630          36% off  \n",
       "3         ₹374          81% off  \n",
       "4         ₹373          62% off  \n",
       "5       ₹1,542          55% off  \n",
       "..         ...              ...  \n",
       "96      ₹1,683          51% off  \n",
       "97      ₹1,948          44% off  \n",
       "98        ₹499          66% off  \n",
       "99        ₹399          60% off  \n",
       "100     ₹1,578          54% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand=[]\n",
    "prod1=[]\n",
    "prod2=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "for page in range(0,3):\n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    for j in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'):\n",
    "        prod1.append(j.text)\n",
    "    \n",
    "    for c in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]'):\n",
    "        prod2.append(c.text)\n",
    "    prod=prod1+prod2\n",
    "    \n",
    "    for k in driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]'):\n",
    "        price.append(k.text)\n",
    "    \n",
    "    for l in driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]'):\n",
    "        discount.append(l.text)\n",
    "    \n",
    "    nxt_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "\n",
    "df=pd.DataFrame({'Brand Name':brand, 'Product Name':prod, 'Item Price':price, 'Discount Offered':discount}) #converting scrapped data into dataframe\n",
    "df.index=np.arange(1,len(df)+1) #inserting index numbers\n",
    "df.head(100) #slicing data to show only top 100 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8554cb5",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "\n",
    "Need to Skip as per SME guided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2392b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aadb4ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting webpage https://www.myntra.com/shoes\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e7eda",
   "metadata": {},
   "source": [
    "As the 'INSPECT' option is not accessible, so as per SME direction we need to skip this ques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e70df",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings (need to remove as per SME)\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6ee6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9a29100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get driver to visit defined URL\n",
    "driver.get('https://amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72162525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input command in search bar\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search.send_keys('Laptop')\n",
    "\n",
    "#click on the search button\n",
    "search_button=driver.find_element(By.XPATH,'//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90882eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting “Intel Core i7” processor filter on the page\n",
    "filter_select=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[13]/span/a/div/label/i')\n",
    "filter_select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdc93cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung Galaxy Book2 Intel 12th Gen core i7 39...</td>\n",
       "      <td>79,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td>56,585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...</td>\n",
       "      <td>87,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...</td>\n",
       "      <td>92,690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...</td>\n",
       "      <td>94,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...</td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ASUS Zenbook 14 OLED (2022), 14\" (35.56 cms) 2...</td>\n",
       "      <td>1,04,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title     Price\n",
       "1   Lenovo Ideapad Gaming 3 Intel Core i7 10th Gen...    62,990\n",
       "2   Samsung Galaxy Book2 Intel 12th Gen core i7 39...    79,490\n",
       "3   ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...    56,585\n",
       "4   HP Pavilion 14 12th Gen Intel Core i7 16GB SDR...    87,990\n",
       "5   Hp Pavilion 15 12Th Gen Intel Core I7 16Gb Sdr...    92,690\n",
       "6   Fujitsu UH-X 11th Gen Intel Core i7 13.3” FHD ...    84,990\n",
       "7   ASUS VivoBook K15 OLED (2021), 15.6-inch FHD O...    82,990\n",
       "8   Lenovo ThinkPad E14 Intel Core i7 11th Gen 14-...    94,990\n",
       "9   ASUS TUF Gaming F15 (2022), 15.6-inch (39.62 c...  1,09,990\n",
       "10  ASUS Zenbook 14 OLED (2022), 14\" (35.56 cms) 2...  1,04,990"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "price=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-none puis-padding-right-small s-title-instructions-style\"]'): #scrapping title from the page\n",
    "    title.append(i.text)\n",
    "    \n",
    "for k in driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]'): #scrapping price data from the page\n",
    "    price.append(k.text)\n",
    "\n",
    "df2=pd.DataFrame({'Title':title, 'Price':price}) #converting scrapped data into dataframe\n",
    "df2.index=np.arange(1,len(df2)+1) #inserting index numbers\n",
    "df2.head(10) #slicing data to top 10 search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7d575",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1dac3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec4a309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get driver to visit defined URL\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a996e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the jobs option\n",
    "jobs_click=driver.find_element(By.XPATH,'/html/body/div[1]/nav[2]/div/ul/li[5]/a')\n",
    "jobs_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c33de7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input command in the search bar\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "search.send_keys('Data Scientist')\n",
    "\n",
    "#click on the search button\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33bbbe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on location icon\n",
    "location=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]')\n",
    "location.click()\n",
    "\n",
    "#entering \"Noida\" in location search\n",
    "place=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "place.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ef3b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the search button\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60f7b058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of Days posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CBRE South Asia Pvt Ltd</td>\n",
       "      <td>8d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>1d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Genpact</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>11d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>15d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>28d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SOPRA STERIA INDIA LIMITED</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>17d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Company Name No. of Days posted Rating\n",
       "1                          CBRE South Asia Pvt Ltd             8d ago    4.3\n",
       "2                    GENPACT India Private Limited             1d ago    4.0\n",
       "3                                          Genpact             3d ago    4.0\n",
       "4         Ericsson India Global Services Pvt. Ltd.            18d ago    4.3\n",
       "5                    GENPACT India Private Limited            11d ago    4.0\n",
       "6   Optum Global Solutions (India) Private Limited            15d ago    4.1\n",
       "7   Optum Global Solutions (India) Private Limited            16d ago    4.1\n",
       "8         Ericsson India Global Services Pvt. Ltd.            28d ago    4.3\n",
       "9                       SOPRA STERIA INDIA LIMITED            17d ago    4.2\n",
       "10                EXL Services.com ( I ) Pvt. Ltd.            17d ago    3.9"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company=[]\n",
    "days=[]\n",
    "rating=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]'): #scrapping days posted data from page\n",
    "    days.append(i.text)\n",
    "del days[1:20:2] #deleting unwanted data\n",
    "\n",
    "for j in driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]'): #scrapping company name from page\n",
    "    company.append(j.text)\n",
    "    \n",
    "for k in driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]'): #scrapping rating from page\n",
    "    rating.append(k.text)\n",
    "\n",
    "dfff=pd.DataFrame({'Company Name':company, 'No. of Days posted':days, 'Rating':rating}) #converting scrapped data into dataframe\n",
    "dfff.index=np.arange(1,len(dfff)+1) #inserting index numbers\n",
    "dfff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348ed04",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14d1e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#command to run chrome\n",
    "driver=webdriver.Chrome(r'chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d8bd00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get driver to visit defined URL\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b83f3f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary option selection\n",
    "salary_selection=driver.find_element(By.XPATH,'/html/body/div[1]/nav[2]/div/ul/li[3]/a')\n",
    "salary_selection.click()\n",
    "\n",
    "#drop down menu option selection\n",
    "browser=driver.find_element(By.XPATH,'/html/body/div[1]/nav[2]/div/ul/li[3]/div/ul/li[1]/div/div[2]/p')\n",
    "browser.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8202d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input command in the search bar\n",
    "search=driver.find_element(By.XPATH,'//input[@class=\"tt-input\"]')\n",
    "search.send_keys('Data Scientist')\n",
    "\n",
    "#selecting the desrired option from the drop down menu\n",
    "search_click=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]')\n",
    "search_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c66e14f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Based on Salaries</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 31.7L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>based on 53 salaries</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optum</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>based on 48 salaries</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 16.5L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZS</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "      <td>based on 33 salaries</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.7L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>based on 109 salaries</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 15.2L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>based on 65 salaries</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>4 yrs experience</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>3 yrs experience</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 14.1L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "      <td>based on 91 salaries</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>₹ 13.6L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ford Motor</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "      <td>based on 21 salaries</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Company Name           Experience      Based on Salaries  \\\n",
       "1                      Walmart  3-4 yrs experience    based on 22 salaries   \n",
       "2                     Ab Inbev  2-4 yrs experience    based on 53 salaries   \n",
       "3                        Optum  2-4 yrs experience    based on 48 salaries   \n",
       "4                           ZS  1-2 yrs experience    based on 33 salaries   \n",
       "5            Fractal Analytics  2-4 yrs experience   based on 109 salaries   \n",
       "6              Tiger Analytics  2-4 yrs experience    based on 65 salaries   \n",
       "7   Legato Health Technologies    4 yrs experience    based on 11 salaries   \n",
       "8                     Tredence    3 yrs experience    based on 12 salaries   \n",
       "9                 UnitedHealth  2-4 yrs experience    based on 91 salaries   \n",
       "10                  Ford Motor  3-4 yrs experience    based on 21 salaries   \n",
       "\n",
       "   Min Salary Avg Salary Max Salary  \n",
       "1     ₹ 25.0L    ₹ 31.7L    ₹ 45.0L  \n",
       "2     ₹ 15.0L    ₹ 19.7L    ₹ 25.5L  \n",
       "3     ₹ 11.0L    ₹ 16.5L    ₹ 22.6L  \n",
       "4     ₹ 11.0L    ₹ 15.7L    ₹ 22.0L  \n",
       "5      ₹ 9.0L    ₹ 15.2L    ₹ 23.0L  \n",
       "6      ₹ 9.0L    ₹ 14.7L    ₹ 20.0L  \n",
       "7     ₹ 11.0L    ₹ 14.5L    ₹ 20.0L  \n",
       "8      ₹ 8.8L    ₹ 14.1L    ₹ 17.5L  \n",
       "9      ₹ 8.0L    ₹ 13.6L    ₹ 20.5L  \n",
       "10    ₹ 10.0L    ₹ 13.5L    ₹ 18.0L  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company=[]\n",
    "exp=[]\n",
    "bsal=[]\n",
    "minsal=[]\n",
    "avgsal=[]\n",
    "maxsal=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]/a'): #scrapping company name from page\n",
    "    company.append(i.text.split(\"\\n\"))\n",
    "a=sum(company,[]) #merging all data in one list\n",
    "del a[1:20:2] #delete unwated data from the list\n",
    "\n",
    "for j in driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]'): #scrapping minimum salary data from page\n",
    "    minsal.append(j.text)\n",
    "del minsal[1:20:2] #delete unwated data from the list\n",
    "\n",
    "for k in driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]'): #scrapping maximum salary data from page\n",
    "    maxsal.append(k.text)\n",
    "del maxsal[0:20:2] #delete unwated data from the list\n",
    "\n",
    "for l in driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]'): #scrapping average salary data from page\n",
    "    avgsal.append(l.text)\n",
    "\n",
    "for m in driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]'): #scrapping experience data from page\n",
    "    exp.append(m.text.split('('))\n",
    "b=sum(exp,[]) #merging all data in one list\n",
    "del b[1:20:2] #delete unwanted data from the list\n",
    "\n",
    "for n in driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]/span'): #scrapping based on no. of salaries from page\n",
    "    bsal.append(n.text.replace('(','').replace(')',''))\n",
    "\n",
    "df=pd.DataFrame({'Company Name':a, 'Experience':b, 'Based on Salaries':bsal, 'Min Salary':minsal, 'Avg Salary':avgsal, 'Max Salary':maxsal}) #converting scrapped data into dataframe\n",
    "df.index=np.arange(1,len(df)+1) #inserting index numbers\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3ea6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
